[
    {
        "ref": "https://dengxiujun.github.io/blog/oracle_reademe/",
        "title": "oracle 记录",
        "section": "blog",
        "date" : "2019.04.01",
        "body": " 01. dmp文件导入步骤 01) 用管理员登录:\n# 方法一 system as sysdba # 方法二 sys as sysdba  02) 创建用户\nCREATE USER \u0026lt;USERNAME\u0026gt; IDENTIFIED BY \u0026lt;PASSWORD\u0026gt;;  03) 赋权限给新用户\nGRANT CREATE USER, DROP USER, ALTER USER, CREATE ANY VIEW, DROP ANY VIEW, EXP_FULL_DATABASE, IMP_FULL_DATABASE, DBA, CONNECT, RESOURCE, CREATE SESSION TO \u0026lt;用户名\u0026gt;;  04) 打开cmd窗口\nIMP \u0026lt;USERNAME\u0026gt;/\u0026lt;PASSWORD\u0026gt;@\u0026lt;SID\u0026gt; FILE=D:\\\\XXX.DMP FULL=Y;  05) 导出命令:\n# 导出某些指定的表: exp \u0026lt;username\u0026gt;/\u0026lt;password\u0026gt;@\u0026lt;SID\u0026gt; file=d:\\\\xxx.dmp tables=(table1,table2,table3) # 导出某个用户的表: exp \u0026lt;username\u0026gt;/\u0026lt;password\u0026gt;@\u0026lt;SID\u0026gt; file=d:\\\\xxx.dmp owner=\u0026lt;username\u0026gt;  02. 常用操作 01) 切换用户\n# 方式一 CONNECT SYS/123456 AS SYSDBA; # 方式二 CONN SCOTT/TIGER;  02) 退出sqlplus:\nEXIT;  03) 免登录进入 sqlplus:\n# 方式一 sqlplus /nolog # 方式二 sqlplus / as sysdba  04) 查询表信息:\nDESC \u0026lt;TABLENAME\u0026gt;;  05) 表结构修改字段:\nALTER TABLE \u0026lt;TABLE_NAME\u0026gt; MODIFY (\u0026lt;FIELD_NAME\u0026gt; \u0026lt;FIELD_TYPE\u0026gt;);  06) 表结构增加字段:\nALTER TABLE \u0026lt;TABLE_NAME\u0026gt; ADD \u0026lt;FIELD_NAME\u0026gt; \u0026lt;FIELD_TYPE\u0026gt;;  07) 表结构增加注释:\nCOMMENT ON COLUMN \u0026lt;TABLE_NAME\u0026gt;.\u0026lt;FIELD_NAME\u0026gt; IS '\u0026lt;COMMENT_CONTENT\u0026gt;';  08) 显示当前用户:\nSHOW USER;  09) 解锁用户:\nALTER USER \u0026lt;USERNAME\u0026gt; ACCOUNT UNLOCK;  10) 修改用户密码:\nALTER USER \u0026lt;USERNAME\u0026gt; IDENTIFIED BY \u0026lt;NEW_PASSWORD\u0026gt;;  11) 显示当前数据库实例:\n# 方式一 SHOW PARAMETER INTANCE; # 方式二 SELECT INSTANCE_NAME FROM V$INSTANCE;  12) sql语句case when 的用法:\ncase when \u0026lt;condition\u0026gt; then \u0026lt;what to do when condition is true\u0026gt; else \u0026lt;what to do when condition is false\u0026gt; end  13) 表结构字段名称修改:\nALTER TABLE \u0026lt;TABLE_NAME\u0026gt; RENAME COLUMN \u0026lt;OLD_FIELD_NAME\u0026gt; TO \u0026lt;NEW_FIELD_NAME\u0026gt;;  03.GRANT 赋于权限 常用的系统权限集合有以下三个:\nCONNECT(基本的连接), RESOURCE(程序开发), DBA(数据库管理)\n常用的数据对象权限有以下五个:\nALL ON 数据对象名, SELECT ON 数据对象名, UPDATE ON 数据对象名, DELETE ON 数据对象名, INSERT ON 数据对象名, ALTER ON 数据对象名\nGRANT CONNECT, RESOURCE TO \u0026lt;TABLE_NAME\u0026gt;; GRANT SELECT ON \u0026lt;TABLE_NAME\u0026gt; TO \u0026lt;USER_NAME\u0026gt;; GRANT SELECT, INSERT, DELETE ON \u0026lt;TABLE_NAME\u0026gt; TO \u0026lt;USER_NAME\u0026gt;, \u0026lt;USER_NAME\u0026gt;;  04.REVOKE 回收权限 REVOKE CONNECT, RESOURCE FROM \u0026lt;USER_NAME\u0026gt;; REVOKE SELECT ON \u0026lt;TABLE_NAME\u0026gt; FROM \u0026lt;USER_NAME\u0026gt;; REVOKE SELECT, INSERT, DELETE ON \u0026lt;TABLE_NAME\u0026gt; FROM \u0026lt;USER_NAME\u0026gt;, \u0026lt;USER_NAME\u0026gt;;  05. 重建并修改默认临时表空间办法: 01) 查询当前数据库默认临时表空间名和查询临时表空间数据文件\nselect * from database_properties where property_name='DEFAULT_TEMP_TABLESPACE'; select tablespace_name,file_name,bytes/1024/1024 file_size,autoextensible from dba_temp_files;  02) 创建新的临时表空间\ncreate temporary tablespace temp02 tempfile 'E:\\oracle\\oradata\\lims\\TEMP02.DBF' size 1024M autoextend on;  03) 修改默认表空间为刚刚建立的临时表空间\nalter database default temporary tablespace temp02;  04) 查看用户所用临时表空间的情况\nSELECT USERNAME,TEMPORARY_TABLESPACE FROM DBA_USERS;  05) 删除原来的临时表空间\ndrop tablespace temp including contents and datafiles;  06) 查看所有表空间名确认临时表空间是否已删除\nselect tablespace_name from dba_tablespaces;  06. 临时表空间相关处理 01) 查询默认临时表空间\nselect * from database_properties where property_name='DEFAULT_TEMP_TABLESPACE';  02) 查询临时表空间数据文件状态:\nselect tablespace_name,file_name,bytes/1024/1024 file_size,autoextensible from dba_temp_files;  03) 创建新的临时表空间\ncreate temporary tablespace temp_01 tempfile '/u01/app/oracle/oradata/XE/temp_01.dbf' size 1024M autoextend on;  04) 修改默认表空间为新的表空间\nalter database default temporary tablespace temp_01;  05) 修改临时表空间大小\nalter database tempfile '/u01/app/oracle/oradata/XE/temp.dbf' resize 512m;  06) 设置临时表空间自动增长\nalter database tempfile '/u01/app/oracle/oradata/XE/temp.dbf' autoextend on next 8m maxsize unlimited;  07) 查看临时表空间使用情况:\nSELECT tbs 表空间名, SUM(totalM) 总共大小M, SUM(usedM) 已使用空间M, SUM(remainedM) 剩余空间M, SUM(usedM) / SUM(totalM) * 100 已使用百分比, SUM(remainedM) / SUM(totalM) * 100 剩余百分比 FROM ( SELECT tb.file_id ID, tb.tablespace_name tbs, tb.file_name NAME, tb.bytes / 1024 / 1024 totalM, (tb.bytes - SUM(NVL(ta.free_space, 0))) / 1024 / 1024 usedM, SUM(NVL(ta.free_space, 0) / 1024 / 1024) remainedM, SUM(NVL(ta.free_space, 0) /(tb.bytes) * 100), (100 - (SUM(NVL(ta.free_space, 0)) /(tb.bytes) * 100)) FROM dba_temp_free_space ta, dba_temp_files tb WHERE ta.tablespace_name = tb.tablespace_name GROUP BY tb.tablespace_name, tb.file_name, tb.file_id, tb.bytes ORDER BY tb.tablespace_name ) GROUP BY tbs;  07. 表空间相关处理 01) 扩展表空间\nalter database datafile '/u01/app/oracle/oradata/XE/system.dbf' resize 1024m;  02) 表空间自动增长\nalter system datafile '/u01/app/oracle/oradata/XE/system_01.dbf' autoextend on next 50m maxsize 500m;  03) 新增表空间数据文件\nalter tablespace system add datafile '/u01/app/oracle/oradata/XE/system_01.dbf' size 1024m;  04) 查询表空间的所有数据文件\nselect * from dba_data_files where tablespace_name='SYSTEM';  05) 查询表属于哪个表空间\nselect tablespace_name,table_name from user_talbes where table_name='employ';  06) 查看表空间使用情况\nSELECT tbs 表空间名, SUM(totalM) 总共大小M, SUM(usedM) 已使用空间M, SUM(remainedM) 剩余空间M, SUM(usedM) / SUM(totalM) * 100 已使用百分比, SUM(remainedM) / SUM(totalM) * 100 剩余百分比 FROM ( SELECT tb.file_id ID, tb.tablespace_name tbs, tb.file_name NAME, tb.bytes / 1024 / 1024 totalM, (tb.bytes - SUM(NVL(ta.bytes, 0))) / 1024 / 1024 usedM, SUM(NVL(ta.bytes, 0) / 1024 / 1024) remainedM, SUM(NVL(ta.bytes, 0) /(tb.bytes) * 100), (100 - (SUM(NVL(ta.bytes, 0)) /(tb.bytes) * 100)) FROM dba_free_space ta, dba_data_files tb WHERE ta.file_id = tb.file_id GROUP BY tb.tablespace_name, tb.file_name, tb.file_id, tb.bytes ORDER BY tb.tablespace_name ) GROUP BY tbs;  00. 其它备忘 01) sql语句和sql命令虽然大小写都可以, 但是建议大写, 大写执行速度快, 同时有些命令只能大写!\n02) sql语句和sql命令必须用分号结尾, cmd中的命令不用分号!\n03) sqlplus 登录密码区分大小写 04) 查询 DIRECTORY 操作需要的权限\nSELECT DISTINCT PRIVILEGE FROM DBA_SYS_PRIVS WHERE PRIVILEGE LIKE '%DIRECTORY%';  05) 查询当前设定的目录配置\nSELECT * FROM DBA_DIRECTORIES;  06) 赋予SCOTT用户删除和创建目录配置的权限\nGRANT DROP ANY DIRECTORY, CREATE ANY DIRECTORY TO SCOTT;  07) 回收SCOTT用户删除和创建目录配置的权限\nREVOKE DROP ANY DIRECTORY, CREATE ANY DIRECTORY FROM SCOTT;  08) 创建某个目录配置\nCREATE OR REPLACE DIRECTORY \u0026lt;dir_name\u0026gt; AS \u0026lt;dir_path\u0026gt;;  09) 删除某个目录配置\nDROP DIRECTORY \u0026lt;dir_name\u0026gt;;  10) 赋予和回收某个目录的读写权限:\nGRANT READ ON DIRECTORY \u0026lt;dir_name\u0026gt; TO SCOTT; GRANT WRITE ON DIRECTORY \u0026lt;dir_name\u0026gt; TO SCOTT; REVOKE READ ON DIRECTORY \u0026lt;dir_name\u0026gt; FROM SCOTT; REVOKE WRITE ON DIRECTORY \u0026lt;dir_name\u0026gt; FROM SCOTT;  11) 查询当前schma下的所有表: SELECT T.* FROM USER_TABLES T;\n12) 查出所有表和对应schma以及表的字段\nSELECT DISTINCT DCC.OWNER AS \u0026quot;用户\u0026quot;, DCC.TABLE_NAME AS \u0026quot;表名\u0026quot;, DCC.COLUMN_NAME AS \u0026quot;字段名\u0026quot;, DTC.DATA_TYPE AS \u0026quot;数据类型\u0026quot;, DCC.COMMENTS AS \u0026quot;字段描述\u0026quot;, (CASE WHEN CONSTS.COLUMN_NAME IS NOT NULL THEN '是' ELSE '' END) AS \u0026quot;是否主键\u0026quot; FROM DBA_TAB_COLS DTC LEFT JOIN DBA_COL_COMMENTS DCC ON (DTC.COLUMN_NAME = DCC.COLUMN_NAME AND DTC.TABLE_NAME = DCC.TABLE_NAME AND DTC.OWNER = DCC.OWNER) LEFT JOIN DBA_TAB_COMMENTS UTC ON (DTC. OWNER = UTC. OWNER AND DTC.TABLE_NAME = UTC.TABLE_NAME) LEFT JOIN (SELECT CU.* FROM DBA_CONS_COLUMNS CU, DBA_CONSTRAINTS AU WHERE CU.CONSTRAINT_NAME = AU.CONSTRAINT_NAME AND AU.CONSTRAINT_TYPE = 'P' ) CONSTS ON (DTC.OWNER = CONSTS.OWNER AND DTC.TABLE_NAME = CONSTS.TABLE_NAME AND DTC.COLUMN_NAME = CONSTS.COLUMN_NAME) WHERE DTC.OWNER IN ('BOMMGMT', 'CFGMGMT', 'CHGMGMT', 'CORE', 'CUST', 'MSTDATA', 'INTEGRATION') ORDER BY DCC.OWNER, DCC.TABLE_NAME;  13) 数据库死锁查询\nselect s.username,l.object_id, l.session_id,s.serial#, s.lockwait,s.status,s.machine,s.program from v$session s,v$locked_object l where s.sid = l.session_id; select sql_text from v$sql where hash_value in (select sql_hash_value from v$session where sid in (select session_id from v$locked_object)); select distinct 'alter system kill session ''' ||sid||','||serial#||''''||';' as \u0026quot;kill sql\u0026quot; from V$locked_object t1 left join V$session t2 on t1.session_id = t2.sid;  14) 约束查询: SELECT UC.TABLE_NAME, UC.CONSTRAINT_NAME, UC.* FROM USER_CONSTRAINTS UC;\n15) 查询所有列名: SELECT * FROM ALL_TAB_COLS WHERE TABLE_NAME = \u0026lsquo;XXX\u0026rsquo;;\n16) 查找alert日志, 需要通过 sqlplus / as sysdba 登陆, 然后输入: show parameter dump;\n附件 oracle记录txt版本\n"
    }
,
    {
        "ref": "https://dengxiujun.github.io/blog/after_copy_vm_do/",
        "title": "VMware虚拟机转VitrualBOX虚拟机等后续优化操作",
        "section": "blog",
        "date" : "2019.04.01",
        "body": " 01. VMware虚拟机转VitrualBox虚拟机 01) 打开cmd，并切换到VMware的安装目录下的OVFTool目录\nd: # 盘符切换 cd D:\\VMware\\VMware Workstation\\OVFTool  02) 使用 ovftool 命令转换格式\novftool \u0026quot;D:\\Virtual Machines\\prd_170_vm\\prd_170.vmx\u0026quot; \u0026quot;D:\\VirtualMachines\\prd_170_vb\\prd_170.ovf\u0026quot;  注：需要 D:\\VirtualMachines\\prd_170_vm\\prd_170.vmx 该虚拟机处于关机状态\n03) 打开VitrualBOX主界面，依次打开\u0026rdquo;管理\u0026rdquo;\u0026gt;\u0026gt;\u0026ldquo;导入虚拟电脑\u0026rdquo;，在弹出界面中选择 D:\\VirtualMachines\\prd_170_vb\\prd_170.ovf\n04) 处理网卡配置等，如果有安装\u0026rdquo;VM增强插件\u0026rdquo;，可以删除之后安装\u0026rdquo;VitrualBox增强插件\u0026rdquo;\n02. VMware磁盘格式vmdk转VirtualBox磁盘格式vdi 01) 打开cmd，并切换到VitrualBox安装目录\nd: # 盘符切换 cd D:\\VirtualBox  02) 使用 VBoxManage.exe clonehd 命令克隆并格式化磁盘格式\nVBoxManage.exe clonehd \u0026quot;D:\\Virtual Machines\\prd_6.170_vb\\prd_6.170.vmdk\u0026quot; \u0026quot;D:\\Virtual Machines\\prd_6.170_vb\\prd_6.170.vdi\u0026quot; --format VDI  03) 上述命令执行到90%的时间点会报错误，错误信息如下，原因是克隆的磁盘和原磁盘uuid重复，此时可以修改原磁盘和新磁盘其中一个的uuid，使用命令如下\nProgress state: E_INVALIDARG VBoxManage.exe: error: Failed to clone medium VBoxManage.exe: error: Cannot register the hard disk 'D:\\Virtual Machines\\prd_6.170_vb\\prd_6.170.vdi' {4cb06e65-d214-4361-b9c6-b5faf1f5effa} because a hard disk 'D:\\Virtual Machines\\prd_6.170_vb\\prd_6.170.vdi' with UUID {0160913f-6e83-4cd6-97b7-c9e24d9cd26d} already exists VBoxManage.exe: error: Details: code E_INVALIDARG (0x80070057), component VirtualBoxWrap, interface IVirtualBox VBoxManage.exe: error: Context: \u0026quot;enum RTEXITCODE __cdecl handleCloneMedium(struct HandlerArg *)\u0026quot; at line 954 of file VBoxManageDisk.cpp VBoxManage.exe internalcommands sethduuid \u0026quot;D:\\Virtual Machines\\prd_6.170_vb\\prd_6.170.vdi\u0026quot;  04) 打开VirtualBox主界面，依次选择\u0026rdquo;管理\u0026rdquo;\u0026gt;\u0026gt;\u0026ldquo;虚拟介质管理\u0026rdquo;，在弹出界面中选中原来的vmdk磁盘并使用右键释放和删除该vmdk介质 05) 打开转换后的虚拟机的设置界面，\u0026rdquo;存储\u0026rdquo;\u0026gt;\u0026gt;\u0026ldquo;控制器\u0026rdquo;\u0026gt;\u0026gt;\u0026ldquo;添加虚拟硬盘\u0026rdquo;，然后在弹出界面中选择转换后的dvi磁盘 03. 磁盘扩容 方案一：使用\u0026rdquo;VBoxManage modifyhd\u0026rdquo;命令\n打开cmd，并切换到VitrualBox安装目录执行以下命令\nVBoxManage modifyhd \u0026ldquo;D:\\Virtual Machines\\prd_6.170\\prd_6.170.vdi\u0026rdquo; –-resize 102400\n注：该命令只支持vdi格式的磁盘\n方案二：针对不同操作系统采用新增磁盘挂载方式\nlinux参考 http://www.linuxidc.com/Linux/2011-02/32083.htm\nwindows请自行百度\n"
    }
,
    {
        "ref": "https://dengxiujun.github.io/blog/hadoop_cluster_build/",
        "title": "HADOOP(3.0.0)在CENTOS7(RED HAT 7)下完全分布式环境搭建",
        "section": "blog",
        "date" : "2019.03.29",
        "body": " 一、环境简介 本教程服务器主机都是CentOS 7(Red Hat 7 亦可)，集群结点分布情况如下表：\n+---------------+-----------+---------------------------------- |IP |HOSTNAME |备注 +---------------+-----------+---------------------------------- |192.168.6.171 |hdpmmaster |ResourceManager 进程所在机器 +---------------+-----------+---------------------------------- |192.168.6.172 |hdpsmaster |SecondaryNameNode 主机的备机 +---------------+-----------+---------------------------------- |198.168.6.67 |hdpslave67 |datanode +---------------+-----------+---------------------------------- |198.168.6.68 |hdpslave68 |datanode +---------------+-----------+---------------------------------- |198.168.6.69 |hdpslave68 |datanode +---------------+-----------+----------------------------------  二、Linux 环境准备 01. 创建hadoop用户 01) 新建用户: adduser hadoop(注: 在创建hadoop用户的同时也创建了hadoop用户组)\n02) 给hadoop用户添加登录密码: passwd hadoop\n03) 把hadoop用户加入到hadoop用户组: usermod -a -G hadoop hadoop\n03) 赋予用户root权限, 向/etc/sudoers中添加\u0026rdquo;hadoop ALL=(ALL) ALL\u0026rdquo;，如果没有写的权限需要先执行 chmod +w /etc/sudoers\n注：以上所有操作都是在root用户下完成，非root用户可以在所有命令前加sudo\n02. HOSTNAME 处理 01) 修改服务器的 hostname，使用命令 hostnamectl set-hostname \n+---------------+---------------------------------------------- +IP |command +---------------+---------------------------------------------- |192.168.6.171 |hostnamectl set-hostname hdpmmaster +---------------+---------------------------------------------- |192.168.6.172 |hostnamectl set-hostname hdpsmaster +---------------+---------------------------------------------- |192.168.6.67 |hostnamectl set-hostname hdpslave67 +---------------+---------------------------------------------- |192.168.6.68 |hostnamectl set-hostname hdpslave68 +---------------+---------------------------------------------- |192.168.6.69 |hostnamectl set-hostname hdpslave69 +---------------+----------------------------------------------  02) 向/etc/hosts文件中添加域名和IP的映射，内容如下\n192.168.6.171 hdpmmaster 192.168.6.172 hdpsmaster 192.168.6.67 hdpslave67 192.168.6.68 hdpslave68 192.168.6.69 hdpslave69  注：以上所有操作都是在root用户下完成，非root用户可以在所有命令前加sudo\n03. ssh免密码登录 01) ssh安装，使用命令 sudo yum isntall -y openssd\n02) ssh dsa算法密钥对生成，分别在5台机器执行以下3条命令\nssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa cat ~/.ssh/id_dsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys  03) 复制公钥到集群服务器，使用命令 ssh-copy-id @, 示例：复制 hdpslave67(192.168.6.67) 的公钥到 hdpslave68(192.168.6.68)\n注：可以执行 ssh hadoop@hdpslave68 命令看是否需要输入登录密码来确认是否陈功，同时避免以后检查出什么问题最好保证集群中的服务器能够两两无密码登录。\n04. JDK 安装 01) 下载 jdk 的 rpm 安装文件\n02) 使用命令 sudo rpm -ivh jdk-8u144-linux-x64.rpm 安装\n03) JDK 环境变量配置：sudo vi /etc/profile\nexport JAVA_HOME=/usr/java/jdk1.8.0_144 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=$CLASSPATH:.:${JAVA_HOME}/lib:${JAVA_HOME}/jre/lib export PATH=${JAVA_HOME}/bin:${JAVA_HOME}/jre/bin:$PATH  注：jdk的环境变量配置也可写入 hadoop 用户目录下的 .bashrc 文件，或者 .bash_profile 文件\n05. 关闭所有服务器的防火墙 sudo systemctl stop firewalld #停止防火墙服务\nsudo systemctl disable firewalld #禁用防火墙服务开机启动\n三、HAOOP 安装以及配置 01) 下载并安装 hadoop (版本：3.0.0)\nwget http://mirrors.shuosc.org/apache/hadoop/common/hadoop-3.0.0/hadoop-3.0.0.tar.gz tar -xzf hadoop-3.0.0.tar.gz -C /usr/local/ cd /usr/local/ ln -s hadoop-3.0.0/ hadoop #建立软链接, 也可直接使用 mv hadoop-3.0.0 hadoop 命令改名  02) 配置 hadoop 环境变量，向 /home/hadoop/.bashrc 文件添加以下内容\n# HADOOP export HADOOP_HOME=/usr/local/hadoop export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop export HADOOP_INSTALL=$HADOOP_HOME export HADOOP_MAPRED_HOME=$HADOOP_HOME export HADOOP_COMMON_HOME=$HADOOP_HOME export HADOOP_HDFS_HOME=$HADOOP_HOME export HADOOP_YARN_HOME=$HADOOP_HOME export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native  03) 配置 hadoop 安装目录(/usr/local/hadoop)下的 etc/hadoop/core-site.xml\n\u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://hdpmmaster:9000\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.tmp.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///usr/local/hadoop/hdptmp\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;Abase for other temporary directories.\u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; 04) 配置 hadoop 安装目录(/usr/local/hadoop)下的 etc/hadoop/hdfs-site.xml \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;1\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.name.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///usr/local/hadoop/hadoop_data/hdfs/namenode\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.datanode.data.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///usr/local/hadoop/hadoop_data/hdfs/datanode\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.secondary.http-address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdpsmaster:9868\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; 05) 配置 hadoop 安装目录(/usr/local/hadoop)下的 etc/hadoop/mapred-site.xml \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;mapreduce.framework.name\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;yarn\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;mapreduce.jobhistory.address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdpmmaster:10020\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;mapreduce.jobhistory.webapp.address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdpmmaster:19888\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;  06) 配置 hadoop 安装目录(/usr/local/hadoop)下的 etc/hadoop/yarn-site.xml\n\u0026lt;configuration\u0026gt; \u0026lt;!-- Site specific YARN configuration properties --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.aux-services\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;mapreduce_shuffle\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.env-whitelist\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.resource.cpu-vcores\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;2\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.resource.memory-mb\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;3072\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.scheduler.maximum-allocation-mb\u0026gt;\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;3052\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.scheduler.address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdpmmaster:8030\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.resource-tracker.address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdpmmaster:8031\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdpmmaster:8032\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.admin.address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdpmmaster:8033\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.webapp.address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdpmmaster:8088\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.vmem-check-enabled\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;false\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;  07) 配置 hadoop 安装目录(/usr/local/hadoop)下的 etc/hadoop/workers\nhdpsmaster hdpslave67 hdpslave68 hdpslave69  注：该 workers 文件也可以配置为ip，如下\n192.168.6.171 192.168.6.67 192.168.6.68 192.168.6.69  08) 配置 hadoop 安装目录(/usr/local/hadoop)下的 etc/hadoop/hadoop-env.sh\nexport JAVA_HOME=/usr/java/latest #去掉前面的\u0026rsquo;#\u0026lsquo;, 且写入jdk的安装路径, 这里的写法用latest是为了以后jdk升级不用修改该配置, 当然也可以写jdk安装的绝对路径, 即\u0026rdquo;/usr/java1.8.0_144\u0026rdquo;\n09) 格式化namenode\nhdfs namenode -format\n注：格式化之前需要将剩余的主机都如此配置hadoop，最简单的做法就是配置好一台，然后直接复制到剩余的主机服务器上。同时后续可能需要修改配置文件每次都需要同步配置文件，可以写个简单的同步脚本，内容如下。\n# 名称: scphdp.sh # 路径: /usr/local/hadoop # 备注: 01. 需要添加执行权限, chmod +x /usr/local/hadoop/scphdp.sh # 02. 注意修改集群的ip echo \u0026quot;==========6.67 begin==========\u0026quot; scp -r etc/hadoop hadoop@192.168.6.67:/usr/local/hadoop/etc echo \u0026quot;===========6.67 end===========\u0026quot; echo \u0026quot;==========6.68 begin==========\u0026quot; scp -r etc/hadoop hadoop@192.168.6.68:/usr/local/hadoop/etc echo \u0026quot;===========6.68 end===========\u0026quot; echo \u0026quot;==========6.69 begin==========\u0026quot; scp -r etc/hadoop hadoop@192.168.6.69:/usr/local/hadoop/etc echo \u0026quot;===========6.69 end===========\u0026quot; #echo \u0026quot;==========6.172 begin==========\u0026quot; #scp -r etc/hadoop hadoop@192.168.6.172:/usr/local/hadoop/etc #echo \u0026quot;===========6.172 end===========\u0026quot;  10) 启动集群\nstart-all.sh  注：启动之后通过 jps 命令查看java后台进程，各个结点的java进程信息如下\n+---------------+-----------+-------------------------------------------------- |IP |HOSTNAME |java进程 +---------------+-----------+-------------------------------------------------- |192.168.6.171 |hdpmmaster |ResourceManager, NameNode, Jps +---------------+-----------+-------------------------------------------------- |192.168.6.172 |hdpsmaster |Jps, SecondaryNameNode, NodeManager, DataNode +---------------+-----------+-------------------------------------------------- |198.168.6.67 |hdpslave67 |NodeManager, Jps, DataNode +---------------+-----------+-------------------------------------------------- |198.168.6.68 |hdpslave68 |NodeManager, Jps, DataNode +---------------+-----------+-------------------------------------------------- |198.168.6.69 |hdpslave68 |NodeManager, Jps, DataNode +---------------+-----------+--------------------------------------------------  11) 在有图形界面的pc上访问下面两个地址链接，查看相关信息\nhttp://hdpmmaster:8088/ #NameNode图形界面, 任务分配和任务进度信息的查询 http://hdpmmaster:9870/ #集群结点(Node Of Cluster)图形界面\n注：以域名访问需要向该pc的hosts文件中加入 \u0026ldquo;192.168.6.171 hdpmmaster\u0026rdquo;，Windows 操作系统的hosts文件路径在 \u0026ldquo;C:\\Windows\\System32\\drivers\\etc\\hosts\u0026rdquo;，CentOS操作系统的hosts文件路径在 \u0026ldquo;/etc/hosts\u0026rdquo;。\n12) 单词统计示例运行\nhadoop fs -mkdir /input hadoop fs -chmod -R 775 /input hadoop fs -put /usr/local/hadoop/LICENSE.txt /input hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar wordcount /input /output  注:\n\u0026emsp;\u0026emsp;01. 每次执行上面的 hadoop jar 命令，需要确认集群结点上的 /output 目录是否存在，存在则使用命令 \u0026ldquo;hadoop fs -rmr -f /output\u0026rdquo;删除该目录\n\u0026emsp;\u0026emsp;02. 执行成功之后可以在 http://hdpmmaster:9870/explorer.html 中的\u0026rdquo;/output\u0026rdquo;文件夹中找到输出结果，允许下载和预览该结果文件\n13) 停止集群\nstop-all.sh\n14) 任务历史服务启动与关闭，web访问地址是 http://hdpmmaster:19888/jobhistory/ 端口是在mapred-site.xml中配置的\nmapred \u0026ndash;daemon start historyserver #启动\nmapred \u0026ndash;daemon stop historyserver #关闭\n四、FAQ 01. 物理内存或虚拟内存监测溢出 问题描述: 执行任务的时虚拟内存溢出\n报错信息: Container [pid=5623,containerID=container_1514514155753_0001_01_000002] is running beyond virtual memory limits. Current usage: 155.1 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.\n解决方案:\n\u0026emsp;\u0026emsp;方案一: 关闭虚拟内存监测, 在yarn-site.xml文件中添加\u0026rdquo;yarn.nodemanager.vmem-check-enabled\u0026rdquo;配置, 值为\u0026rdquo;false\u0026rdquo;(该方案不建议在正式环境中使用)\n\u0026emsp;\u0026emsp;方案二: 提高内存配置, 参考 http://blog.chinaunix.net/uid-25691489-id-5587957.html\n02. datanode和namenode都启动成功，但datanode没有与namenode关联成功 问题描述: 集群启动正常, 使用jps查看各个结点的java进程也是对的, 但是无法打开http://hdpmmaster:8088, 虽然http://hdpmmaster:9870能访问, 但是查看 DataNode 页面没有看到任何一个结点。\n报错信息: 查看任何一个 DataNode 结点的日志文件(HADOOP_HOME/logs/hadoop-hadoop-datanode-hdpsmaster.log)含有: Retrying connect to server: hdpmmaster/192.168.6.171:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n解决方案: 查看 hdpmmaster/192.168.6.171 主机的hosts文件中是否有\u0026rdquo;127.0.0.1 hdpmmaster\u0026rdquo;, 删除该行, 重新格式化集群(hdfs namenode -format).\n问题原因: 因为将hdpmmaster映射在了localhost, 所以DataNode结点无法访问到该NameNode, 同时也无法打开http://hdpmmaster:8088. 可以通过查看格式化集群结点时最后的提示信息来判定是否有出现该问题. 如果是\u0026rdquo;SHUTDOWN_MSG: Shutting down NameNode at localhost/127.0.0.1\u0026rdquo;, 表示映射错误; 如果是\u0026rdquo;SHUTDOWN_MSG: Shutting down NameNode at hdpmmaster/192.168.6.171\u0026rdquo;, 表示映射是正确的. 当然这一切都要在所有集群主机能够互相ping通的前提下, 即需要的所有端口都开放, 或者直接关闭防火墙, 该教程为简洁就是直接关闭集群所有主机的防火墙.\n03. unhealthy状态的datanode处理(下面只是该现象其中一种原因) 问题描述: 在http://hdpmmaster:8088/cluster/nodes 的界面出现unhealthy结点\n报错信息: yarn.server.nodemanager.DirectoryCollection: Directory /var/lib/hadoop-yarn/cache/yarn/nm-local-dir error, used space above threshold of 90.0%, removing from list of valid directories\n解决方案: 加大磁盘容量, 或者清理磁盘空间, 当然也可以提高yarn的监测数值, 即在yarn-site.xml中添加\u0026rdquo;yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage\u0026rdquo;配置, 值是一个百分比数值, 例如、\u0026rdquo;95.0\u0026rdquo;\n问题原因: 该结点主机的磁盘使用超过90%,\n"
    }
,
    {
        "ref": "https://dengxiujun.github.io/blog/devops_introduction/",
        "title": "DevOps 简介",
        "section": "blog",
        "date" : "2019.03.29",
        "body": " 目标  打造\u001b通用, \u001b稳定, 快速, 易于扩展的部署流水线  部署流水线是指软件从版本控制库到用户手中这一过程的自动化表现形式。对软件的每次变更都会经历这样一个自动化的过程 部署流水线包含\u001b\u001b代码检查, 持续集成, 持续\u0008\u001b部署, 自动化测试等各个环节  构建自助平台  \u0008各项目组\u001b可一键创建测试所以需要的容器化Java环境, 数据库等. 并可通过自助平台进行管理 通过自助平台配置自动构建行为 集成日志查看功能   \u0008\u0008\u001b参考示例 零件俱乐部项目的部署流程如下图所示, 开发人员无需关心部署的细节, 只需要推送代码到对应的分支, 就会触发部署\u001b\u001b流水线部署到相应的环境.\n 开发人员使用特性分支的git分支模型来开发新功能, \u001b\u001b代码需要推送到GitLab仓库 GitLab根据代码仓库中的gitlab-ci.yaml文件来, 触发GitLab CI执行 编译-\u0026gt;测试-\u0026gt;发布镜像-\u0026gt;部署 流水线  \u0008\u0008特定的处理环节(比如多个feature分支的自动合并, 版本号的确定) 采用Shell或者Python脚本来实现 Java代码的构建会用到Gradle, js代码的构建会用到npm或yarn 执行单元测试, 如果测试失败会终止构建, 并使用邮件通知给本次构建的\u001b触发者 编译完成之后从代码仓库中获取Dockerfile文件, 然后使用Docker\u001b制作成镜像文件  发布到Harbor, harbor是docker镜像的仓库,\u0008 基于官方的\u0008Registry 通过kubectl触发Kubernetes执行发布流程 k8s拉取指定镜像, 进行滚动升级  书单 DevOps方法论  《凤凰项目：一个IT运维的传奇故事》 以小说的方式，讲述了一个凌乱的无可救药的运维项目组是如何一步步达成最后高效且舒心的工作状态。\n 《DevOps实践指南》 《凤凰项目：一个IT运维的传奇故事》 的姊妹篇， 涵盖了DevOps的横向知识，可以当工具书读。\n 《持续交付》\n 《Effective DevOps》\n  源代码管理/Linux系统  《git pro》 网络资源， 免费\n 《Unix \u0026amp; Linux大学教程》 Linux, Shell 学习的经典书籍\n  容器化：  《第一本Docker书》 《自己动手写Docker》  容器编排  《Kubernetes中文指南》 《Kubernetes in Action》 官网教程  分布式存储  《Learning Ceph》 《Ceph设计原理与实现》  自动化测试 (\u001b待补充) 单元测试, ui自动化测试 等\n自动化运维 Ansible\n日志 Elasticsearch, Logstash/Fluentd, Kibana\n监控 Prometheus\n路线图 "
    }
,
    {
        "ref": "https://dengxiujun.github.io/blog/emoji-support/",
        "title": "Emoji Support",
        "section": "blog",
        "date" : "2019.03.05",
        "body": "Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site’s configuration and then you can type emoji shorthand codes directly in content files; e.g.\n🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\nN.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n.emoji { font-family: Apple Color Emoji,Segoe UI Emoji,NotoColorEmoji,Segoe UI Symbol,Android Emoji,EmojiSymbols; }"
    }
]
